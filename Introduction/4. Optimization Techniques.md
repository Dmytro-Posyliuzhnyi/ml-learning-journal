
# Normal Equation

The **Normal Equation** is a mathematical formula used to calculate the optimal parameters (coefficients) for a linear regression model. It is a **closed-form solution**, meaning it provides the answer directly without the need for iterative methods like *gradient descent*. This makes it a simple and efficient method for solving linear regression problems when the dataset is relatively small.

### Formula
The Normal Equation is expressed as:

$`\boldsymbol{w} = \left( \boldsymbol{X}^\top \boldsymbol{X} \right)^{-1} \boldsymbol{X}^\top \boldsymbol{y}`$

Where:
- $`\boldsymbol{X}`$: The design matrix (includes the features and bias term),
- $`\boldsymbol{y}`$: The vector of target values,
- $`\boldsymbol{w}`$: The vector of model parameters (weights).

---

# Gradient Descent

**Gradient Descent** is an optimization technique used to minimize a function, typically the **loss function** in machine learning, by iteratively adjusting model parameters like weights $`w`$ and bias $`b`$. 
The goal is to find the values that reduce the error.


### Key Concepts
- **Gradient**: The gradient is a generalization of the slope to multiple dimensions. In one dimension, the slope is simply the derivative, but in higher dimensions,
  the gradient is a **vector** of partial derivatives with respect to each parameter. It tells you the direction of the steepest ascent.
  To minimize the function, we move in the opposite direction, steepest descent, that's why we have name **Gradient Descent**.

- **Learning Rate (Î±)**: A small positive value that determines the size of the steps taken during the gradient update. In more rigorous words: "The learning rate
  determines the magnitude of the changes to make to the weights and bias during each step of the gradient descent process."


## Epochs in Gradient Descent

An **epoch** refers to one complete pass through the entire training dataset. Each epoch consists of multiple steps where the model's parameters are updated 
based on the gradient of the loss function.

## Until Convergence

The phrase "until convergence" means the process continues until the model's parameters stop changing significantly. This happens when:
- The change in the loss function between epochs is small.
- The gradients become very close to zero.

At this point, the model has found the best parameters (or is very close to it), and further updates don't improve performance significantly.

## Types of Gradient Descent

Gradient descent can be very sensitive to choice of the learning rate $`\alpha`$. It can be also slow for large datasets. Fortunately, there are several improved versions of gradient descent. Typical gradient descent uses the entire training set to compute the gradients, which can be computationally expensive for large datasets.
**Stochastic Gradient Descent (SGD)**, on the other hand, uses only a single example or a small subset of the training set to compute the gradients, which makes it more computationally efficient. **Mini-Batch Gradient Descent** strikes a balance between **Gradient Descent** and **SGD** by computing the gradient based on a **small subset of data points** (mini-batch). There are a lot of other improvements of **GD** which are out of the scope of this introduction notes.

## Implementation

In [Gradient Descent.py](https://github.com/Dmytro-Posyliuzhnyi/ml-learning-journal/blob/main/Introduction/Code/Gradient%20Descent.py) I've included a basic implementation of gradient descent that tries to find the best model parameters to predict sales based on spending on radio advertising. I used Jupyter to execute it. The dataset was found on the wiki for the book "Hundred Page Machine Learning".

<img width="500" alt="Page 1" src="https://github.com/user-attachments/assets/f66cfb4a-5ecd-4eab-8d1d-10df3765b239">
