
# Normal Equation

The **Normal Equation** is a mathematical formula used to calculate the optimal parameters (coefficients) for a linear regression model. It is a **closed-form solution**, meaning it provides the answer directly without the need for iterative methods like *gradient descent*. This makes it a simple and efficient method for solving linear regression problems when the dataset is relatively small.

### Formula
The Normal Equation is expressed as:

$`\boldsymbol{w} = \left( \boldsymbol{X}^\top \boldsymbol{X} \right)^{-1} \boldsymbol{X}^\top \boldsymbol{y}`$

Where:
- $`\boldsymbol{X}`$: The design matrix (includes the features and bias term),
- $`\boldsymbol{y}`$: The vector of target values,
- $`\boldsymbol{w}`$: The vector of model parameters (weights).


From what I understand, the *LinearRegression* class in *scikit-learn* uses *ordinary least squares* function, which is still a *closed-form* solution. From what my intuition tells me at the moment, it is essentially a more optimized form of the normal equation, which, for example, uses *Singular Value Decomposition* for the computation of the matrix pseudoinverse.

Also, I finally connected different concepts in my mind related to optimization terms like *MSE*, *RMSE*, *Least Squares*, etc. From what I understand, algorithms try to minimize the cost function, such as *MSE*. *Ordinary Least Squares (OLS)* is just one of the optimization techniques that minimizes the cost function, but it does so in a *closed-form* way. In contrast, *gradient descent* can also use MSE (which, from what I've read, is common for linear regression) but the difference is that it uses an iterative approach.

---

# Gradient Descent

**Gradient Descent** is an optimization technique used to minimize a function, typically the **loss function** in machine learning, by iteratively adjusting model parameters like weights $`w`$ and bias $`b`$. 
The goal is to find the values that reduce the error.


### Key Concepts
- **Gradient**: The gradient is a generalization of the slope to multiple dimensions. In one dimension, the slope is simply the derivative, but in higher dimensions,
  the gradient is a **vector** of partial derivatives with respect to each parameter. It tells you the direction of the steepest ascent.
  To minimize the function, we move in the opposite direction, steepest descent, that's why we have name **Gradient Descent**.

- **Learning Rate (Î±)**: A small positive value that determines the size of the steps taken during the gradient update. In more rigorous words: "The learning rate
  determines the magnitude of the changes to make to the weights and bias during each step of the gradient descent process."


## Epochs in Gradient Descent

An **epoch** refers to one complete pass through the entire training dataset. Each epoch consists of multiple steps where the model's parameters are updated 
based on the gradient of the loss function.

## Until Convergence

The phrase "until convergence" means the process continues until the model's parameters stop changing significantly. This happens when:
- The change in the loss function between epochs is small.
- The gradients become very close to zero.

At this point, the model has found the best parameters (or is very close to it), and further updates don't improve performance significantly.

## Types of Gradient Descent

### Batch Gradient Descent

Batch gradient descent, also called vanilla gradient descent, calculates the error for each instance within the training dataset, but it only gets updated (makes steps downhill) per epoch. Number of epochs is considered a hyperparameter. If it is too low, we will stop far away from the optimal solution; but if it is too high, we will waste time while the  model parameters do not change anymore. A simple solution is to set a very large number of epochs but to interrupt the algorithm when the gradient vector becomes tiny - that is, when its norm becomes smaller than a tiny number $`\epsilon`$ (called *tolerance*) - because this happens when gradient descent has (almost) reached the minimum. 

So as we can see, there are two important hyperparameters: $`\eta = \text{learning rate}`$ and $`\epsilon = \text{tolerance}`$.

**Convergence Rate**

When the cost function is convex and its slope does not change abruptly (as is the case for the MSE cost function), batch gradient descent with a fixed learning rate will eventually converge to the optimal solution, but you may have to wait a while: it can take $`O(\frac{1}{\epsilon})`$ iterations to reach the optimum within a range of $`\epsilon`$, depending on the shape of the cost function. If you divide the tolerance by 10 to have a more precise solution, then the algorithm may have to run about 10 times longer.


## Implementation

In [Gradient Descent.py](https://github.com/Dmytro-Posyliuzhnyi/ml-learning-journal/blob/main/Introduction/Code/Gradient%20Descent.py) I've included a basic implementation of gradient descent that tries to find the best model parameters to predict sales based on spending on radio advertising. I used Jupyter to execute it. The dataset was found on the wiki for the book "Hundred Page Machine Learning".

<img width="500" alt="Page 1" src="https://github.com/user-attachments/assets/f66cfb4a-5ecd-4eab-8d1d-10df3765b239">

When using *gradient descent* we should ensure that all features have a similar scale, or else it will take much longer to converge.
